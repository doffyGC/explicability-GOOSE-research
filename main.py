"""
Pipeline completo de treinamento e avalia√ß√£o de modelo XGBoost.

Este script implementa as melhores pr√°ticas acad√™micas:
1. Separa√ß√£o correta de treino/teste (hold-out)
2. Valida√ß√£o cruzada K-Fold estratificada
3. C√°lculo de m√©tricas com intervalos de confian√ßa
4. An√°lise de explicabilidade com SHAP
5. Otimiza√ß√µes pra lidar com datasets grandes
"""

import os
from config import *
from data.loader import load_dataset
from data.preprocess import preprocess
from model.train import train_model
from model.evaluate import evaluate_models, save_metrics_report
from explainability.shap_analysis import run_shap

def main():
    """
    Fun√ß√£o principal que executa todo o pipeline.
    """

    print("\n" + "=" * 60)
    print("PIPELINE DE TREINAMENTO E AVALIA√á√ÉO - XGBoost")
    print("=" * 60)
    print()

    # ========================================
    # ETAPA 1: Carregamento dos Dados
    # ========================================

    print("=" * 60)
    print("ETAPA 1: Carregamento dos Dados")
    print("=" * 60)

    if not os.path.exists(DATASET_PATH):
        raise FileNotFoundError(f"Dataset n√£o encontrado: {DATASET_PATH}")

    print(f"Carregando dataset: {DATASET_PATH}")
    df = load_dataset(DATASET_PATH, sample_size=SAMPLE_SIZE, random_state=RANDOM_STATE)
    print(f"‚úì Dataset carregado: {df.shape[0]} linhas √ó {df.shape[1]} colunas")
    print()

    # ========================================
    # ETAPA 2: Pr√©-processamento
    # ========================================

    print("=" * 60)
    print("ETAPA 2: Pr√©-processamento")
    print("=" * 60)

    # Separa features (X) e target (y)
    X, y, encoder = preprocess(df, target_column="class", discarted_columns=DISCARTED_COLUMNS)

    print(f"‚úì Features: {X.shape[1]} colunas")
    print(f"‚úì Amostras: {len(y)}")
    print(f"‚úì Classes: {CLASS_NAMES}")
    print(f"‚úì Distribui√ß√£o de classes:")

    # Mostra a distribui√ß√£o de classes (importante pra detectar desbalanceamento)
    for i, cls in enumerate(CLASS_NAMES):
        count = (y == i).sum()
        percentage = (count / len(y)) * 100
        print(f"    - {cls}: {count} amostras ({percentage:.1f}%)")
    print()

    # Libera mem√≥ria do DataFrame original
    del df

    # ========================================
    # ETAPA 3: Treinamento
    # ========================================

    # Exibe qual modelo foi escolhido
    model_desc = MODEL_DESCRIPTIONS.get(MODEL_PARAMS.__class__.__name__, "")
    canonical_model = MODEL_NAME_ALIASES.get(MODEL_TYPE.lower(), MODEL_TYPE)
    print("=" * 60)
    print(f"MODELO ESCOLHIDO: {canonical_model.upper()}")
    print(f"Description: {MODEL_DESCRIPTIONS.get(canonical_model, canonical_model)}")
    print("=" * 60)
    print()

    # Treina modelos usando valida√ß√£o cruzada + hold-out test set
    cv_models, final_model, X_test, y_test = train_model(
        X, y,
        model_type=MODEL_TYPE,
        params=MODEL_PARAMS.get(canonical_model, XGBOOST_PARAMS),
        n_splits=N_SPLITS,
        seed=RANDOM_STATE,
        test_size=TEST_SIZE
    )

    # ========================================
    # ETAPA 4: Avalia√ß√£o
    # ========================================

    # Avalia modelos da CV e o modelo final
    cv_metrics, test_metrics, kappa_mean, kappa_ci, test_kappa, test_cm, cv_total_cm = evaluate_models(
        cv_models, final_model, X_test, y_test, CLASS_NAMES
    )

    # ========================================
    # ETAPA 5: Resultados Finais
    # ========================================

    print("=" * 60)
    print("RESULTADOS FINAIS")
    print("=" * 60)
    print()

    print("üìä VALIDA√á√ÉO CRUZADA (M√©dia ¬± IC 95%):")
    print("-" * 60)
    for i, cls in enumerate(CLASS_NAMES):
        print(f"\n{cls}:")
        print(f"  F1-score:  {cv_metrics['F1-score Mean'][i]:.4f} ¬± {cv_metrics['F1-score CI'][i]:.4f}")
        print(f"  Precision: {cv_metrics['Precision Mean'][i]:.4f} ¬± {cv_metrics['Precision CI'][i]:.4f}")
        print(f"  Recall:    {cv_metrics['Recall Mean'][i]:.4f} ¬± {cv_metrics['Recall CI'][i]:.4f}")
        print(f"  Accuracy:  {cv_metrics['Accuracy Mean'][i]:.4f} ¬± {cv_metrics['Accuracy CI'][i]:.4f}")

    print(f"\nCohen's Kappa (CV): {kappa_mean:.4f} ¬± {kappa_ci:.4f}")
    print()

    print("üéØ TESTE FINAL (Hold-out - Conjunto nunca visto):")
    print("-" * 60)
    for i, cls in enumerate(CLASS_NAMES):
        print(f"\n{cls}:")
        print(f"  F1-score:  {test_metrics['F1-score'][i]:.4f}")
        print(f"  Precision: {test_metrics['Precision'][i]:.4f}")
        print(f"  Recall:    {test_metrics['Recall'][i]:.4f}")
        print(f"  Accuracy:  {test_metrics['Accuracy'][i]:.4f}")

    print(f"\nCohen's Kappa (Teste): {test_kappa:.4f}")
    print()

    # ========================================
    # ETAPA 5.1: Salvar Relat√≥rio de M√©tricas
    # ========================================

    print("=" * 60)
    print("SALVANDO RELAT√ìRIOS")
    print("=" * 60)
    print()

    # Extrai o nome do dataset do caminho
    dataset_name = os.path.basename(DATASET_PATH).replace(".csv", "").replace(".parquet", "")

    # Salva relat√≥rios em Markdown e Log
    md_path, log_path = save_metrics_report(
        cv_metrics, test_metrics, kappa_mean, kappa_ci, test_kappa,
        test_cm, CLASS_NAMES, dataset_name, output_dir=PATH_BASE, cv_total_cm=cv_total_cm
    )

    print(f"‚úì Relat√≥rio Markdown salvo: {md_path}")
    print(f"‚úì Relat√≥rio Log salvo: {log_path}")
    print()

    # ========================================
    # ETAPA 6: Explicabilidade (SHAP)
    # ========================================

    # Descomenta abaixo pra gerar os gr√°ficos SHAP
    # ATEN√á√ÉO: pode demorar bastante dependendo do tamanho do dataset!

    print("=" * 60)
    print("ETAPA 6: An√°lise de Explicabilidade (SHAP)")
    print("=" * 60)
    print()
    print("‚ö†Ô∏è  A an√°lise SHAP est√° DESABILITADA por padr√£o.")
    print("    Pra habilitar, descomente as linhas no final do main.py")
    print("    (pode demorar v√°rios minutos dependendo do dataset!)")
    print()

    # Descomenta as linhas abaixo pra rodar o SHAP:
    # run_shap(
    #     final_model,
    #     X_test,
    #     CLASS_NAMES,
    #     dataset_name=dataset_name,
    #     path_base=PATH_BASE,
    #     graphics=GRAPHICS,
    #     sample_percentage=SHAP_SAMPLE_PERCENTAGE,
    #     random_state=RANDOM_STATE
    # )

    print("=" * 60)
    print("‚úì PIPELINE CONCLU√çDO COM SUCESSO!")
    print("=" * 60)
    print()


if __name__ == "__main__":
    main()